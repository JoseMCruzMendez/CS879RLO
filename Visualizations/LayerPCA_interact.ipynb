{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b45b681",
   "metadata": {},
   "source": [
    "# From scratch\n",
    "\n",
    "Run it from start and some necessary files will be saved"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbad35d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:29.091877Z",
     "start_time": "2025-11-14T14:22:26.444187Z"
    }
   },
   "source": [
    "!pip install ipywidgets"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(85949) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/josecruz/anaconda3/lib/python3.10/site-packages (8.1.0)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipywidgets) (5.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipywidgets) (3.0.8)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipywidgets) (4.0.8)\r\n",
      "Requirement already satisfied: stack-data in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: decorator in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\r\n",
      "Requirement already satisfied: appnope in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\r\n",
      "Requirement already satisfied: backcall in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: pure-eval in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /Users/josecruz/anaconda3/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "f02f1f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:29.848466Z",
     "start_time": "2025-11-14T14:22:29.411207Z"
    }
   },
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(85952) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001B[32mOK\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:30.311348Z",
     "start_time": "2025-11-14T14:22:30.306386Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from NNModel import MultiLayerNN\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from prep_data import prep_data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "abbc64da6240c02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:34.146056Z",
     "start_time": "2025-11-14T14:22:30.626246Z"
    }
   },
   "source": [
    "train_loader, test_loader = prep_data()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "state_dict = torch.load(\"data/model.pt\", weights_only=True)\n",
    "\n",
    "new_dict = {}\n",
    "#When model compiles, all weights are modified from LAYERNAME to _orig_model.LAYERNAME. We remove the _orig_model. for compatibility\n",
    "for k in state_dict.keys():\n",
    "    new_dict[k[10:]] = state_dict[k]\n",
    "\n",
    "model = MultiLayerNN(latent_size=128, num_layers=3)\n",
    "model.load_state_dict(new_dict)\n",
    "model.to(device)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for loader in [train_loader, test_loader]:\n",
    "    for image, label, idxs in loader:\n",
    "        images.append(image.squeeze().reshape(-1, 28*28))\n",
    "        labels.append(label)\n",
    "images = torch.cat(images).to(device)\n",
    "labels = torch.cat(labels).to(device)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6c70b4d5baa6908b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:34.609462Z",
     "start_time": "2025-11-14T14:22:34.474620Z"
    }
   },
   "source": [
    "# Dictionary to store the activations\n",
    "activations = {}\n",
    "# Dictionary to store layer names for plotting titles\n",
    "layer_names = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    \"\"\"Hook function to save the output of a layer\"\"\"\n",
    "    def hook(model, input, output):\n",
    "        # We detach the output tensor to prevent saving the whole computation graph\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register a forward hook for each linear layer\n",
    "# We capture the output of the Linear layer *before* it goes into ReLU\n",
    "hook_handles = []\n",
    "layer_id = 0\n",
    "\n",
    "# Hook for the first linear layer\n",
    "layer_name = f\"Layer {layer_id}: Dim Reduction\"\n",
    "handle = model.dim_reduction.register_forward_hook(get_activation(layer_name))\n",
    "hook_handles.append(handle)\n",
    "layer_names[layer_id] = layer_name\n",
    "layer_id += 1\n",
    "\n",
    "# Hooks for the hidden linear layers\n",
    "for i, layer in enumerate(model.hidden_layers):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        layer_name = f\"Layer {layer_id}: Hidden Linear\"\n",
    "        handle = layer.register_forward_hook(get_activation(layer_name))\n",
    "        hook_handles.append(handle)\n",
    "        layer_names[layer_id] = layer_name\n",
    "        layer_id += 1\n",
    "layer_name = f\"Layer {layer_id}: Output\"\n",
    "handle = model.output.register_forward_hook(get_activation(layer_name))\n",
    "hook_handles.append(handle)\n",
    "layer_names[layer_id] = layer_name\n",
    "\n",
    "# Run a forward pass to trigger the hooks and populate the 'activations' dict\n",
    "with torch.no_grad():\n",
    "    output = model(images)\n",
    "\n",
    "# Don't forget to remove the hooks when you're done to avoid memory leaks\n",
    "for handle in hook_handles:\n",
    "    handle.remove()"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "8832efc75e5107e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:34.983552Z",
     "start_time": "2025-11-14T14:22:34.977966Z"
    }
   },
   "source": [
    "def predict_from_layer(start_layer_index, activation_tensor):\n",
    "    \"\"\"\n",
    "    Takes an activation tensor from a specific layer and passes it\n",
    "    through the rest of the model to get a final prediction.\n",
    "    \"\"\"\n",
    "    x = activation_tensor\n",
    "\n",
    "    # Manually apply the forward pass for subsequent layers\n",
    "    # Apply ReLU for the starting layer (since we hooked pre-relu)\n",
    "    x = nn.functional.relu(x)\n",
    "\n",
    "    # Find the starting point in the hidden_layers list\n",
    "    linear_layer_count = 1 # Start after dim_reduction\n",
    "    start_idx_in_hidden = -1\n",
    "    for i, layer in enumerate(model.hidden_layers):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            if linear_layer_count == start_layer_index:\n",
    "                start_idx_in_hidden = i + 1 # Start from the ReLU after this linear layer\n",
    "                break\n",
    "            linear_layer_count += 1\n",
    "\n",
    "    # Pass through remaining hidden layers\n",
    "    if start_idx_in_hidden != -1:\n",
    "        for i in range(start_idx_in_hidden, len(model.hidden_layers)):\n",
    "            x = model.hidden_layers[i](x)\n",
    "\n",
    "    # Final output layer\n",
    "    if x.shape[1] == 10:\n",
    "        return x\n",
    "    return model.output(x)\n",
    "\n",
    "\n",
    "# # Now, loop through the captured activations and plot\n",
    "# for layer_index, (name, data) in enumerate(activations.items()):\n",
    "#     print(f\"Generating boundary for: {name}\")\n",
    "\n",
    "#     # 1. Fit PCA on this layer's activations\n",
    "#     pca = PCA(n_components=2)\n",
    "#     features_2d = pca.fit_transform(data.cpu().numpy())\n",
    "\n",
    "#     # 2. Create mesh grid\n",
    "#     x_min, x_max = features_2d[:, 0].min()*1.1, features_2d[:, 0].max() *1.1\n",
    "#     y_min, y_max = features_2d[:, 1].min() *1.1, features_2d[:, 1].max() *1.1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "#     # 3. Inverse transform grid points and predict\n",
    "#     grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "#     grid_points_high_dim = pca.inverse_transform(grid_points)\n",
    "#     grid_tensor = torch.tensor(grid_points_high_dim, dtype=torch.float32).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         # Use the helper function to predict from this intermediate layer\n",
    "#         outputs = predict_from_layer(layer_index, grid_tensor)\n",
    "#         _, Z = torch.max(outputs, 1)\n",
    "#         Z = Z.cpu().numpy().reshape(xx.shape)\n",
    "\n",
    "#     # 4. Plotting\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.tab10)\n",
    "#     scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels.cpu(), s=1, cmap=plt.cm.tab10)\n",
    "\n",
    "#     plt.title(f\"Decision Boundary at {name}\")\n",
    "#     plt.xlabel(\"Principal Component 1\")\n",
    "#     plt.ylabel(\"Principal Component 2\")\n",
    "#     plt.legend(handles=scatter.legend_elements()[0], labels=list(range(10)))\n",
    "#     plt.show()"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "3e18df0bfd4ef882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:22:38.790398Z",
     "start_time": "2025-11-14T14:22:35.334004Z"
    }
   },
   "source": [
    "# load incorrect indices & build index mapping\n",
    "from collections import OrderedDict\n",
    "\n",
    "# [(idx, yhat, y), ...]\n",
    "with open(\"data/incorrect_preds.pkl\", \"rb\") as f:\n",
    "    incorrect_triplets = pickle.load(f)\n",
    "\n",
    "incorrect_indices = [t[0] for t in incorrect_triplets]\n",
    "\n",
    "all_indices = []\n",
    "images_list, labels_list = [], []\n",
    "for loader in [train_loader, test_loader]:\n",
    "    for image, label, idxs in loader:\n",
    "        images_list.append(image.squeeze().reshape(-1, 28*28))\n",
    "        labels_list.append(label)\n",
    "        all_indices.append(idxs)\n",
    "\n",
    "images = torch.cat(images_list).to(device)\n",
    "labels = torch.cat(labels_list).to(device)\n",
    "all_indices = torch.cat(all_indices).cpu().numpy()\n",
    "\n",
    "# create mapping from dataset index to row in activations\n",
    "index_to_row = {}\n",
    "for row, idx in enumerate(all_indices):\n",
    "    index_to_row.setdefault(int(idx), row)\n",
    "\n",
    "# Save index mapping for later use\n",
    "with open(\"data/index_to_row.pkl\", \"wb\") as f:\n",
    "    pickle.dump(index_to_row, f)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "358da09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:23:44.640652Z",
     "start_time": "2025-11-14T14:22:39.143157Z"
    }
   },
   "source": [
    "# cache PCA projections and decision boundaries for each layer\n",
    "layer_cache = OrderedDict()\n",
    "labels_per_row = labels.detach().cpu().numpy()\n",
    "\n",
    "for layer_index, (name, data) in enumerate(activations.items()):\n",
    "    print(f\"[cache] {name}\")\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    feats2d = pca.fit_transform(data.cpu().numpy())\n",
    "\n",
    "    # mesh grid\n",
    "    x_min, x_max = feats2d[:, 0].min()*1.1, feats2d[:, 0].max()*1.1\n",
    "    y_min, y_max = feats2d[:, 1].min()*1.1, feats2d[:, 1].max()*1.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_points_high_dim = pca.inverse_transform(grid_points)\n",
    "    grid_tensor = torch.tensor(grid_points_high_dim, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = predict_from_layer(layer_index, grid_tensor)\n",
    "        _, Z = torch.max(outputs, 1)\n",
    "        Z = Z.cpu().numpy().reshape(xx.shape)\n",
    "\n",
    "    layer_cache[name] = {\n",
    "        \"index\": layer_index,\n",
    "        \"pca\": pca,\n",
    "        \"feats2d\": feats2d,\n",
    "        \"labels\": labels_per_row,\n",
    "        \"xx\": xx, \"yy\": yy, \"Z\": Z,\n",
    "    }\n",
    "\n",
    "# Save cache to disk\n",
    "with open(\"data/layer_cache.pkl\", \"wb\") as f:\n",
    "    pickle.dump(layer_cache, f)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cache] Layer 0: Dim Reduction\n",
      "[cache] Layer 1: Hidden Linear\n",
      "[cache] Layer 2: Hidden Linear\n",
      "[cache] Layer 3: Hidden Linear\n",
      "[cache] Layer 4: Output\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "54f33f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:23:45.145192Z",
     "start_time": "2025-11-14T14:23:45.127701Z"
    }
   },
   "source": [
    "# plotting function with highlight\n",
    "\n",
    "incorrect_dict = {idx: (yhat, ytrue) for idx, yhat, ytrue in incorrect_triplets}\n",
    "\n",
    "def plot_all_layers_with_highlight(dataset_idx: int, point_size=10):\n",
    "    if dataset_idx not in index_to_row:\n",
    "        print(f\"[WARN] Index {dataset_idx} is not in the dataset.\")\n",
    "        return\n",
    "\n",
    "    row = index_to_row[dataset_idx]\n",
    "    # true_label = int(labels[row].cpu().item())\n",
    "    true_label = incorrect_dict.get(dataset_idx, (None, None))[1]\n",
    "    pred_label = incorrect_dict.get(dataset_idx, (None, None))[0]\n",
    "\n",
    "    # Plot for each layer\n",
    "    for name, blob in layer_cache.items():\n",
    "        feats2d = blob[\"feats2d\"]\n",
    "        xx, yy, Z = blob[\"xx\"], blob[\"yy\"], blob[\"Z\"]\n",
    "\n",
    "        plt.figure(figsize=(9, 7))\n",
    "        plt.contourf(xx, yy, Z, alpha=0.35, cmap=plt.cm.tab10)\n",
    "        sc = plt.scatter(feats2d[:, 0], feats2d[:, 1],\n",
    "                         c=labels.cpu().numpy(), s=point_size, cmap=plt.cm.tab10)\n",
    "\n",
    "        # Highlight the specific point\n",
    "        hx, hy = feats2d[row, 0], feats2d[row, 1]\n",
    "        plt.scatter([hx], [hy], s=160, facecolors='none', edgecolors='k', linewidths=2.2, marker='o')\n",
    "        plt.scatter([hx], [hy], s=40, c=np.array([true_label]),\n",
    "                    cmap=plt.cm.tab10, vmin=0, vmax=9)  # fill with true label color\n",
    "\n",
    "        plt.title(\n",
    "            f\"Decision Boundary at {name}\\n\"\n",
    "            f\"highlight idx={dataset_idx} | y={true_label}, ŷ={pred_label}\"\n",
    "        )\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.legend(handles=sc.legend_elements()[0], labels=list(range(10)), title=\"True label\", loc=\"best\")\n",
    "        plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "d3c05337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:23:55.179706Z",
     "start_time": "2025-11-14T14:23:45.478961Z"
    }
   },
   "source": [
    "# ---- Interactive selection (fixed) ----\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "\n",
    "incorrect_options = sorted(set(incorrect_indices))\n",
    "if not incorrect_options:\n",
    "    print(\"No misclassified samples found.\")\n",
    "else:\n",
    "    dd = widgets.Dropdown(options=incorrect_options, description='Misclassified index:',\n",
    "                          layout={'width': '300px'}, style={'description_width': 'initial'})\n",
    "    btn = widgets.Button(description='Plot', button_style='primary')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def on_click(_):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            plot_all_layers_with_highlight(int(dd.value))\n",
    "\n",
    "    btn.on_click(on_click)\n",
    "\n",
    "    display(widgets.HBox([dd, btn]), out)\n",
    "\n",
    "    # Initial plot\n",
    "    with out:\n",
    "        plot_all_layers_with_highlight(int(dd.value))\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(Dropdown(description='Misclassified index:', layout=Layout(width='300px'), options=(np.int64(38…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7eee78c740c45ebbb1cf6a9e0ae44dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "989bed8e03fe4ae6a9a8b57acb5a3baf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "15b8b367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:23:55.190101Z",
     "start_time": "2025-11-14T14:23:55.187096Z"
    }
   },
   "source": [
    "incorrect_dict.get(233)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "ae6d8d0d",
   "metadata": {},
   "source": [
    "# Use cached layers"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ce22bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:23:55.906065Z",
     "start_time": "2025-11-14T14:23:55.903787Z"
    }
   },
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "860438f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:23:56.301399Z",
     "start_time": "2025-11-14T14:23:56.238203Z"
    }
   },
   "source": [
    "# [(idx, yhat, y), ...]\n",
    "with open(\"data/incorrect_preds.pkl\", \"rb\") as f:\n",
    "    incorrect_triplets = pickle.load(f)\n",
    "\n",
    "with open(\"data/index_to_row.pkl\", \"rb\") as f:\n",
    "    index_to_row = pickle.load(f)\n",
    "\n",
    "with open(\"data/layer_cache.pkl\", \"rb\") as f:\n",
    "    layer_cache = pickle.load(f)\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "86d097e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:24:38.102513Z",
     "start_time": "2025-11-14T14:24:38.088538Z"
    }
   },
   "source": [
    "# plotting function with highlight\n",
    "\n",
    "incorrect_dict = {idx: (yhat, ytrue) for idx, yhat, ytrue in incorrect_triplets}\n",
    "\n",
    "def plot_all_layers_with_highlight(dataset_idx: int, point_size=10):\n",
    "    if dataset_idx not in index_to_row:\n",
    "        print(f\"[WARN] Index {dataset_idx} is not in the dataset.\")\n",
    "        return\n",
    "\n",
    "    row = index_to_row[dataset_idx]\n",
    "    # true_label = int(labels[row].cpu().item())\n",
    "    true_label = incorrect_dict.get(dataset_idx, (None, None))[1]\n",
    "    pred_label = incorrect_dict.get(dataset_idx, (None, None))[0]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "    axs = axs.flatten()\n",
    "    # Plot for each layer\n",
    "    for i, (name, blob) in enumerate(layer_cache.items()):\n",
    "        feats2d = blob[\"feats2d\"]\n",
    "        xx, yy, Z = blob[\"xx\"], blob[\"yy\"], blob[\"Z\"]\n",
    "\n",
    "        plt.figure(figsize=(9, 7))\n",
    "        plt.contourf(xx, yy, Z, alpha=0.35, cmap=plt.cm.tab10)\n",
    "        sc = plt.scatter(feats2d[:, 0], feats2d[:, 1],\n",
    "                         c=blob[\"labels\"], s=point_size, cmap=plt.cm.tab10)\n",
    "\n",
    "        # Highlight the specific point\n",
    "        hx, hy = feats2d[row, 0], feats2d[row, 1]\n",
    "        plt.scatter([hx], [hy], s=160, facecolors='none', edgecolors='k', linewidths=2.2, marker='o')\n",
    "        plt.scatter([hx], [hy], s=40, c=np.array([true_label]),\n",
    "                    cmap=plt.cm.tab10, vmin=0, vmax=9)  # fill with true label color\n",
    "\n",
    "        plt.title(\n",
    "            f\"Decision Boundary at {name}\\n\"\n",
    "            f\"highlight idx={dataset_idx} | y={true_label}, ŷ={pred_label}\"\n",
    "        )\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.legend(handles=sc.legend_elements()[0], labels=list(range(10)), title=\"True label\", loc=\"best\")\n",
    "        plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "c785bff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:24:45.942369Z",
     "start_time": "2025-11-14T14:24:38.978557Z"
    }
   },
   "source": [
    "# ---- Interactive selection (fixed) ----\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "incorrect_indices = [t[0] for t in incorrect_triplets]\n",
    "incorrect_options = sorted(set(incorrect_indices))\n",
    "if not incorrect_options:\n",
    "    print(\"No misclassified samples found.\")\n",
    "else:\n",
    "    dd = widgets.Dropdown(options=incorrect_options, description='Misclassified index:',\n",
    "                          layout={'width': '300px'}, style={'description_width': 'initial'})\n",
    "    btn = widgets.Button(description='Plot', button_style='primary')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def on_click(_):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            plot_all_layers_with_highlight(int(dd.value))\n",
    "\n",
    "    btn.on_click(on_click)\n",
    "\n",
    "    display(widgets.HBox([dd, btn]), out)\n",
    "\n",
    "    # Initial plot\n",
    "    with out:\n",
    "        plot_all_layers_with_highlight(int(dd.value))\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(Dropdown(description='Misclassified index:', layout=Layout(width='300px'), options=(np.int64(38…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11a573c5e2884c568d17f0e874344402"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09b97c0cb320472da068ea21f9028af5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "acbac93d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:24:04.128766Z",
     "start_time": "2025-11-14T14:24:04.126732Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
