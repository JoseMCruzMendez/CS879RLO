{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b45b681",
   "metadata": {},
   "source": [
    "# From scratch\n",
    "\n",
    "Run it from start and some necessary files will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbad35d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipywidgets) (5.14.0)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.12)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shiyunwa/anaconda3/envs/deeplearning/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02f1f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:51:07.249769Z",
     "start_time": "2025-10-03T19:51:03.155705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from NNModel import MultiLayerNN\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from prep_data import prep_data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbc64da6240c02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T20:03:24.579523Z",
     "start_time": "2025-10-03T20:03:20.951942Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = prep_data()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "state_dict = torch.load(\"data/model.pt\", weights_only=True)\n",
    "\n",
    "new_dict = {}\n",
    "#When model compiles, all weights are modified from LAYERNAME to _orig_model.LAYERNAME. We remove the _orig_model. for compatibility\n",
    "for k in state_dict.keys():\n",
    "    new_dict[k[10:]] = state_dict[k]\n",
    "\n",
    "model = MultiLayerNN(latent_size=128, num_layers=3)\n",
    "model.load_state_dict(new_dict)\n",
    "model.to(device)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for loader in [train_loader, test_loader]:\n",
    "    for image, label, idxs in loader:\n",
    "        images.append(image.squeeze().reshape(-1, 28*28))\n",
    "        labels.append(label)\n",
    "images = torch.cat(images).to(device)\n",
    "labels = torch.cat(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c70b4d5baa6908b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T20:09:09.308925Z",
     "start_time": "2025-10-03T20:09:09.277858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to store the activations\n",
    "activations = {}\n",
    "# Dictionary to store layer names for plotting titles\n",
    "layer_names = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    \"\"\"Hook function to save the output of a layer\"\"\"\n",
    "    def hook(model, input, output):\n",
    "        # We detach the output tensor to prevent saving the whole computation graph\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register a forward hook for each linear layer\n",
    "# We capture the output of the Linear layer *before* it goes into ReLU\n",
    "hook_handles = []\n",
    "layer_id = 0\n",
    "\n",
    "# Hook for the first linear layer\n",
    "layer_name = f\"Layer {layer_id}: Dim Reduction\"\n",
    "handle = model.dim_reduction.register_forward_hook(get_activation(layer_name))\n",
    "hook_handles.append(handle)\n",
    "layer_names[layer_id] = layer_name\n",
    "layer_id += 1\n",
    "\n",
    "# Hooks for the hidden linear layers\n",
    "for i, layer in enumerate(model.hidden_layers):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        layer_name = f\"Layer {layer_id}: Hidden Linear\"\n",
    "        handle = layer.register_forward_hook(get_activation(layer_name))\n",
    "        hook_handles.append(handle)\n",
    "        layer_names[layer_id] = layer_name\n",
    "        layer_id += 1\n",
    "layer_name = f\"Layer {layer_id}: Output\"\n",
    "handle = model.output.register_forward_hook(get_activation(layer_name))\n",
    "hook_handles.append(handle)\n",
    "layer_names[layer_id] = layer_name\n",
    "\n",
    "# Run a forward pass to trigger the hooks and populate the 'activations' dict\n",
    "with torch.no_grad():\n",
    "    output = model(images)\n",
    "\n",
    "# Don't forget to remove the hooks when you're done to avoid memory leaks\n",
    "for handle in hook_handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8832efc75e5107e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T20:20:47.866575Z",
     "start_time": "2025-10-03T20:20:41.530986Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_from_layer(start_layer_index, activation_tensor):\n",
    "    \"\"\"\n",
    "    Takes an activation tensor from a specific layer and passes it\n",
    "    through the rest of the model to get a final prediction.\n",
    "    \"\"\"\n",
    "    x = activation_tensor\n",
    "\n",
    "    # Manually apply the forward pass for subsequent layers\n",
    "    # Apply ReLU for the starting layer (since we hooked pre-relu)\n",
    "    x = nn.functional.relu(x)\n",
    "\n",
    "    # Find the starting point in the hidden_layers list\n",
    "    linear_layer_count = 1 # Start after dim_reduction\n",
    "    start_idx_in_hidden = -1\n",
    "    for i, layer in enumerate(model.hidden_layers):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            if linear_layer_count == start_layer_index:\n",
    "                start_idx_in_hidden = i + 1 # Start from the ReLU after this linear layer\n",
    "                break\n",
    "            linear_layer_count += 1\n",
    "\n",
    "    # Pass through remaining hidden layers\n",
    "    if start_idx_in_hidden != -1:\n",
    "        for i in range(start_idx_in_hidden, len(model.hidden_layers)):\n",
    "            x = model.hidden_layers[i](x)\n",
    "\n",
    "    # Final output layer\n",
    "    if x.shape[1] == 10:\n",
    "        return x\n",
    "    return model.output(x)\n",
    "\n",
    "\n",
    "# # Now, loop through the captured activations and plot\n",
    "# for layer_index, (name, data) in enumerate(activations.items()):\n",
    "#     print(f\"Generating boundary for: {name}\")\n",
    "\n",
    "#     # 1. Fit PCA on this layer's activations\n",
    "#     pca = PCA(n_components=2)\n",
    "#     features_2d = pca.fit_transform(data.cpu().numpy())\n",
    "\n",
    "#     # 2. Create mesh grid\n",
    "#     x_min, x_max = features_2d[:, 0].min()*1.1, features_2d[:, 0].max() *1.1\n",
    "#     y_min, y_max = features_2d[:, 1].min() *1.1, features_2d[:, 1].max() *1.1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "#     # 3. Inverse transform grid points and predict\n",
    "#     grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "#     grid_points_high_dim = pca.inverse_transform(grid_points)\n",
    "#     grid_tensor = torch.tensor(grid_points_high_dim, dtype=torch.float32).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         # Use the helper function to predict from this intermediate layer\n",
    "#         outputs = predict_from_layer(layer_index, grid_tensor)\n",
    "#         _, Z = torch.max(outputs, 1)\n",
    "#         Z = Z.cpu().numpy().reshape(xx.shape)\n",
    "\n",
    "#     # 4. Plotting\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.tab10)\n",
    "#     scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels.cpu(), s=1, cmap=plt.cm.tab10)\n",
    "\n",
    "#     plt.title(f\"Decision Boundary at {name}\")\n",
    "#     plt.xlabel(\"Principal Component 1\")\n",
    "#     plt.ylabel(\"Principal Component 2\")\n",
    "#     plt.legend(handles=scatter.legend_elements()[0], labels=list(range(10)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e18df0bfd4ef882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load incorrect indices & build index mapping\n",
    "from collections import OrderedDict\n",
    "\n",
    "# [(idx, yhat, y), ...]\n",
    "with open(\"data/incorrect_preds.pkl\", \"rb\") as f:\n",
    "    incorrect_triplets = pickle.load(f)\n",
    "\n",
    "incorrect_indices = [t[0] for t in incorrect_triplets]\n",
    "\n",
    "all_indices = []\n",
    "images_list, labels_list = [], []\n",
    "for loader in [train_loader, test_loader]:\n",
    "    for image, label, idxs in loader:\n",
    "        images_list.append(image.squeeze().reshape(-1, 28*28))\n",
    "        labels_list.append(label)\n",
    "        all_indices.append(idxs)\n",
    "\n",
    "images = torch.cat(images_list).to(device)\n",
    "labels = torch.cat(labels_list).to(device)\n",
    "all_indices = torch.cat(all_indices).cpu().numpy()\n",
    "\n",
    "# create mapping from dataset index to row in activations\n",
    "index_to_row = {}\n",
    "for row, idx in enumerate(all_indices):\n",
    "    index_to_row.setdefault(int(idx), row)\n",
    "\n",
    "# Save index mapping for later use\n",
    "with open(\"data/index_to_row.pkl\", \"wb\") as f:\n",
    "    pickle.dump(index_to_row, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358da09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cache] Layer 0: Dim Reduction\n",
      "[cache] Layer 1: Hidden Linear\n",
      "[cache] Layer 2: Hidden Linear\n",
      "[cache] Layer 3: Hidden Linear\n",
      "[cache] Layer 4: Output\n"
     ]
    }
   ],
   "source": [
    "# cache PCA projections and decision boundaries for each layer\n",
    "layer_cache = OrderedDict()\n",
    "labels_per_row = labels.detach().cpu().numpy()\n",
    "\n",
    "for layer_index, (name, data) in enumerate(activations.items()):\n",
    "    print(f\"[cache] {name}\")\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    feats2d = pca.fit_transform(data.cpu().numpy())\n",
    "\n",
    "    # mesh grid\n",
    "    x_min, x_max = feats2d[:, 0].min()*1.1, feats2d[:, 0].max()*1.1\n",
    "    y_min, y_max = feats2d[:, 1].min()*1.1, feats2d[:, 1].max()*1.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_points_high_dim = pca.inverse_transform(grid_points)\n",
    "    grid_tensor = torch.tensor(grid_points_high_dim, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = predict_from_layer(layer_index, grid_tensor)\n",
    "        _, Z = torch.max(outputs, 1)\n",
    "        Z = Z.cpu().numpy().reshape(xx.shape)\n",
    "\n",
    "    layer_cache[name] = {\n",
    "        \"index\": layer_index,\n",
    "        \"pca\": pca,\n",
    "        \"feats2d\": feats2d,\n",
    "        \"labels\": labels_per_row,\n",
    "        \"xx\": xx, \"yy\": yy, \"Z\": Z,\n",
    "    }\n",
    "\n",
    "# Save cache to disk\n",
    "with open(\"data/layer_cache.pkl\", \"wb\") as f:\n",
    "    pickle.dump(layer_cache, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f33f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function with highlight\n",
    "\n",
    "incorrect_dict = {idx: (yhat, ytrue) for idx, yhat, ytrue in incorrect_triplets}\n",
    "\n",
    "def plot_all_layers_with_highlight(dataset_idx: int, point_size=10):\n",
    "    if dataset_idx not in index_to_row:\n",
    "        print(f\"[WARN] Index {dataset_idx} is not in the dataset.\")\n",
    "        return\n",
    "\n",
    "    row = index_to_row[dataset_idx]\n",
    "    # true_label = int(labels[row].cpu().item())\n",
    "    true_label = incorrect_dict.get(dataset_idx, (None, None))[1]\n",
    "    pred_label = incorrect_dict.get(dataset_idx, (None, None))[0]\n",
    "\n",
    "    # Plot for each layer\n",
    "    for name, blob in layer_cache.items():\n",
    "        feats2d = blob[\"feats2d\"]\n",
    "        xx, yy, Z = blob[\"xx\"], blob[\"yy\"], blob[\"Z\"]\n",
    "\n",
    "        plt.figure(figsize=(9, 7))\n",
    "        plt.contourf(xx, yy, Z, alpha=0.35, cmap=plt.cm.tab10)\n",
    "        sc = plt.scatter(feats2d[:, 0], feats2d[:, 1],\n",
    "                         c=labels.cpu().numpy(), s=point_size, cmap=plt.cm.tab10)\n",
    "\n",
    "        # Highlight the specific point\n",
    "        hx, hy = feats2d[row, 0], feats2d[row, 1]\n",
    "        plt.scatter([hx], [hy], s=160, facecolors='none', edgecolors='k', linewidths=2.2, marker='o')\n",
    "        plt.scatter([hx], [hy], s=40, c=np.array([true_label]),\n",
    "                    cmap=plt.cm.tab10, vmin=0, vmax=9)  # fill with true label color\n",
    "\n",
    "        plt.title(\n",
    "            f\"Decision Boundary at {name}\\n\"\n",
    "            f\"highlight idx={dataset_idx} | y={true_label}, ŷ={pred_label}\"\n",
    "        )\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.legend(handles=sc.legend_elements()[0], labels=list(range(10)), title=\"True label\", loc=\"best\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c05337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892e2c4fef104a16982e718006532657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Misclassified index:', layout=Layout(width='300px'), options=(24, 72, 80,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98663ed8b9f04ab6a8367441c5145c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Interactive selection (fixed) ----\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "\n",
    "incorrect_options = sorted(set(incorrect_indices))\n",
    "if not incorrect_options:\n",
    "    print(\"No misclassified samples found.\")\n",
    "else:\n",
    "    dd = widgets.Dropdown(options=incorrect_options, description='Misclassified index:',\n",
    "                          layout={'width': '300px'}, style={'description_width': 'initial'})\n",
    "    btn = widgets.Button(description='Plot', button_style='primary')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def on_click(_):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            plot_all_layers_with_highlight(int(dd.value))\n",
    "\n",
    "    btn.on_click(on_click)\n",
    "\n",
    "    display(widgets.HBox([dd, btn]), out)\n",
    "\n",
    "    # Initial plot\n",
    "    with out:\n",
    "        plot_all_layers_with_highlight(int(dd.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15b8b367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_dict.get(233)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d8d0d",
   "metadata": {},
   "source": [
    "# Use cached layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce22bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860438f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(idx, yhat, y), ...]\n",
    "with open(\"data/incorrect_preds.pkl\", \"rb\") as f:\n",
    "    incorrect_triplets = pickle.load(f)\n",
    "\n",
    "with open(\"data/index_to_row.pkl\", \"rb\") as f:\n",
    "    index_to_row = pickle.load(f)\n",
    "\n",
    "with open(\"data/layer_cache.pkl\", \"rb\") as f:\n",
    "    layer_cache = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d097e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function with highlight\n",
    "\n",
    "incorrect_dict = {idx: (yhat, ytrue) for idx, yhat, ytrue in incorrect_triplets}\n",
    "\n",
    "def plot_all_layers_with_highlight(dataset_idx: int, point_size=10):\n",
    "    if dataset_idx not in index_to_row:\n",
    "        print(f\"[WARN] Index {dataset_idx} is not in the dataset.\")\n",
    "        return\n",
    "\n",
    "    row = index_to_row[dataset_idx]\n",
    "    # true_label = int(labels[row].cpu().item())\n",
    "    true_label = incorrect_dict.get(dataset_idx, (None, None))[1]\n",
    "    pred_label = incorrect_dict.get(dataset_idx, (None, None))[0]\n",
    "\n",
    "    # Plot for each layer\n",
    "    for name, blob in layer_cache.items():\n",
    "        feats2d = blob[\"feats2d\"]\n",
    "        xx, yy, Z = blob[\"xx\"], blob[\"yy\"], blob[\"Z\"]\n",
    "\n",
    "        plt.figure(figsize=(9, 7))\n",
    "        plt.contourf(xx, yy, Z, alpha=0.35, cmap=plt.cm.tab10)\n",
    "        sc = plt.scatter(feats2d[:, 0], feats2d[:, 1],\n",
    "                         c=blob[\"labels\"], s=point_size, cmap=plt.cm.tab10)\n",
    "\n",
    "        # Highlight the specific point\n",
    "        hx, hy = feats2d[row, 0], feats2d[row, 1]\n",
    "        plt.scatter([hx], [hy], s=160, facecolors='none', edgecolors='k', linewidths=2.2, marker='o')\n",
    "        plt.scatter([hx], [hy], s=40, c=np.array([true_label]),\n",
    "                    cmap=plt.cm.tab10, vmin=0, vmax=9)  # fill with true label color\n",
    "\n",
    "        plt.title(\n",
    "            f\"Decision Boundary at {name}\\n\"\n",
    "            f\"highlight idx={dataset_idx} | y={true_label}, ŷ={pred_label}\"\n",
    "        )\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.legend(handles=sc.legend_elements()[0], labels=list(range(10)), title=\"True label\", loc=\"best\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c785bff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9205665e74049eaaf9ae46fc8dbe833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Misclassified index:', layout=Layout(width='300px'), options=(24, 72, 80,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39df1391e0b4593a339f8ec00534b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Interactive selection (fixed) ----\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "incorrect_indices = [t[0] for t in incorrect_triplets]\n",
    "incorrect_options = sorted(set(incorrect_indices))\n",
    "if not incorrect_options:\n",
    "    print(\"No misclassified samples found.\")\n",
    "else:\n",
    "    dd = widgets.Dropdown(options=incorrect_options, description='Misclassified index:',\n",
    "                          layout={'width': '300px'}, style={'description_width': 'initial'})\n",
    "    btn = widgets.Button(description='Plot', button_style='primary')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def on_click(_):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            plot_all_layers_with_highlight(int(dd.value))\n",
    "\n",
    "    btn.on_click(on_click)\n",
    "\n",
    "    display(widgets.HBox([dd, btn]), out)\n",
    "\n",
    "    # Initial plot\n",
    "    with out:\n",
    "        plot_all_layers_with_highlight(int(dd.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbac93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
